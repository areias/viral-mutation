{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNBR9wyflREylyqcMdN4Zry",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/areias/viral-mutation/blob/master/original_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERPBr9RDhJjO"
      },
      "outputs": [],
      "source": [
        "# look at embeddings from original model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connect drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPK0cXeajE0G",
        "outputId": "ffc9c166-90ef-4998-8e5a-f2edf65b3e7a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone repository\n",
        "! git clone https://github.com/brianhie/viral-mutation.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywEJfaUMj1H6",
        "outputId": "d18d8359-012a-4bfe-fd01-de11595253be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'viral-mutation'...\n",
            "remote: Enumerating objects: 1106, done.\u001b[K\n",
            "remote: Counting objects: 100% (216/216), done.\u001b[K\n",
            "remote: Compressing objects: 100% (150/150), done.\u001b[K\n",
            "remote: Total 1106 (delta 131), reused 117 (delta 66), pack-reused 890\u001b[K\n",
            "Receiving objects: 100% (1106/1106), 177.41 MiB | 34.33 MiB/s, done.\n",
            "Resolving deltas: 100% (739/739), done.\n",
            "Checking out files: 100% (84/84), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add mutation to path\n",
        "import sys\n",
        "sys.path.append('viral-mutation/bin')\n",
        "\n"
      ],
      "metadata": {
        "id": "cbdwGrkqj4rz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# arg\n",
        "from collections import namedtuple\n",
        "arguments = namedtuple('arguments', ['model_name',\n",
        "                                     'dim','n_epochs','batch_size',\n",
        "                                     'namespace','seed','checkpoint'])\n",
        "\n",
        "args = arguments('bilstm',512,3,350, # defaults were batch-size 1000, 14 epochs\n",
        "                 'flu',1, \"drive/MyDrive/target/flu/checkpoints/bilstm/bilstm_512-03.hdf5\")\n",
        "args\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOV4WnNkinqm",
        "outputId": "38002c78-5764-4184-ce48-6b3e0a3c104c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "arguments(model_name='bilstm', dim=512, n_epochs=3, batch_size=350, namespace='flu', seed=1, checkpoint='drive/MyDrive/target/flu/checkpoints/bilstm/bilstm_512-03.hdf5')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary\n",
        "AAs = [\n",
        "        'A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H',\n",
        "        'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W',\n",
        "        'Y', 'V', 'X', 'Z', 'J', 'U', 'B', 'Z'\n",
        "    ]\n",
        "    \n",
        "vocabulary = { aa: idx + 1 for idx, aa in enumerate(sorted(AAs)) }"
      ],
      "metadata": {
        "id": "iDqw8W5lilsW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seqs\n",
        "\n",
        "# download data\n",
        "!wget http://cb.csail.mit.edu/cb/viral-mutation/data.tar.gz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha9xDijHijIq",
        "outputId": "7115ea88-8911-4250-83e1-c30b23fb1c8c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-06 13:01:25--  http://cb.csail.mit.edu/cb/viral-mutation/data.tar.gz\n",
            "Resolving cb.csail.mit.edu (cb.csail.mit.edu)... 128.30.2.148\n",
            "Connecting to cb.csail.mit.edu (cb.csail.mit.edu)|128.30.2.148|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3060938794 (2.9G) [application/x-gzip]\n",
            "Saving to: ‘data.tar.gz’\n",
            "\n",
            "data.tar.gz         100%[===================>]   2.85G  63.7MB/s    in 29s     \n",
            "\n",
            "2022-02-06 13:01:55 (99.2 MB/s) - ‘data.tar.gz’ saved [3060938794/3060938794]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip data\n",
        "!tar xvf data.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru0XUJGxkneq",
        "outputId": "4ed5ac51-89e8-43b0-ec32-1793a68c53c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/\n",
            "data/escape_results.txt\n",
            "data/evcouplings/\n",
            "data/evcouplings/flu_h3_config.yaml\n",
            "data/evcouplings/flu_h1_config.yaml\n",
            "data/evcouplings/hiv_bf520_seq.fa\n",
            "data/evcouplings/hiv_env_seq.fa\n",
            "data/evcouplings/hiv_env_config.yaml\n",
            "data/evcouplings/sarscov2_config.yaml\n",
            "data/evcouplings/flu_h1_seq.fa\n",
            "data/evcouplings/hiv_bf520_config.yaml\n",
            "data/evcouplings/sarscov2_seq.fa\n",
            "data/evcouplings/flu_h3_seq.fa\n",
            "data/headlines/\n",
            "data/headlines/abcnews-date-text.csv\n",
            "data/headlines/headlines.txt\n",
            "data/hiv/\n",
            "data/hiv/bg505_regions.txt\n",
            "data/hiv/fitness_haddox2018/\n",
            "data/hiv/fitness_haddox2018/BG505-1_prefs.csv\n",
            "data/hiv/fitness_haddox2018/BG505-3_prefs.csv\n",
            "data/hiv/fitness_haddox2018/BG505-2_prefs.csv\n",
            "data/hiv/fitness_haddox2018/BF520-3_prefs.csv\n",
            "data/hiv/fitness_haddox2018/BF520-2_prefs.csv\n",
            "data/hiv/fitness_haddox2018/BF520-1_prefs.csv\n",
            "data/hiv/fitness_haddox2018/BF520_to_HXB2.csv\n",
            "data/hiv/fitness_haddox2018/BF520_env.fasta\n",
            "data/hiv/fitness_haddox2018/map_indices.py\n",
            "data/hiv/fitness_haddox2018/BF520_avgprefs.csv\n",
            "data/hiv/fitness_haddox2018/Env_protalignment_manualtweaks.fasta\n",
            "data/hiv/fitness_haddox2018/BG505_env.fasta\n",
            "data/hiv/fitness_haddox2018/BG505_avgprefs.csv\n",
            "data/hiv/fitness_haddox2018/BG505_to_HXB2.csv\n",
            "data/hiv/HIV-1_env_samelen.fa\n",
            "data/hiv/escape_dingens2019/\n",
            "data/hiv/escape_dingens2019/FileS4/\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurvive/\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurvive/VRC34.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurvive/PGT151.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurvive/VRC01.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurvive/10E8.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurvive/3BNC117.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurvive/PGT145.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurvive/PGT121.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurvive/101074.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurvive/PG9.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurvive/3BNC117-101074-pool.csv\n",
            "data/hiv/escape_dingens2019/FileS4/.DS_Store\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/PG9.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/PGT151.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/3BNC117.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/3BNC117-101074-pool.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/PGT121.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/101074.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/VRC34.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/PGT145.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/VRC01.csv\n",
            "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/10E8.csv\n",
            "data/hiv/escape_dingens2019/FileS4/diffsel/\n",
            "data/hiv/escape_dingens2019/FileS4/diffsel/PGT121.csv\n",
            "data/hiv/escape_dingens2019/FileS4/diffsel/101074.csv\n",
            "data/hiv/escape_dingens2019/FileS4/diffsel/PGT145.csv\n",
            "data/hiv/escape_dingens2019/FileS4/diffsel/10E8.csv\n",
            "data/hiv/escape_dingens2019/FileS4/diffsel/.DS_Store\n",
            "data/hiv/escape_dingens2019/FileS4/diffsel/PG9.csv\n",
            "data/hiv/escape_dingens2019/FileS4/diffsel/VRC34.csv\n",
            "data/hiv/escape_dingens2019/FileS4/diffsel/3BNC117.csv\n",
            "data/hiv/escape_dingens2019/FileS4/diffsel/3BNC117-101074-pool.csv\n",
            "data/hiv/escape_dingens2019/FileS4/diffsel/VRC01.csv\n",
            "data/hiv/escape_dingens2019/FileS4/diffsel/PGT151.csv\n",
            "data/hiv/escape_dingens2019/BG505_to_HXB2.csv\n",
            "data/hiv/escape_dingens2019/Env_protalign_manualeditAD.fasta\n",
            "data/fitness_results.txt\n",
            "data/influenza/\n",
            "data/influenza/escape_lee2019/\n",
            "data/influenza/escape_lee2019/H3_site_to_PDB_4o5n.csv\n",
            "data/influenza/escape_lee2019/avg_sel_tidy.csv\n",
            "data/influenza/escape_lee2019/Perth2009_H3_HA.fa\n",
            "data/influenza/fitness_wu2020/\n",
            "data/influenza/fitness_wu2020/data_all.csv\n",
            "data/influenza/fitness_wu2020/HA_ecto.fa\n",
            "data/influenza/fitness_wu2020/data_pref.tsv\n",
            "data/influenza/fitness_wu2020/HumanH3N2_All_2018.fa\n",
            "data/influenza/fitness_wu2020/wildtypes.fa\n",
            "data/influenza/escape_doud2018/\n",
            "data/influenza/escape_doud2018/medianfracsurvivefiles/\n",
            "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_FI6v3_median_avgsite.csv\n",
            "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_H17L7_median.csv\n",
            "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_S139_median.csv\n",
            "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_C179_median_avgsite.csv\n",
            "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_H17L7_median_avgsite.csv\n",
            "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_FI6v3_median.csv\n",
            "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_C179_median.csv\n",
            "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_H17L10_median_avgsite.csv\n",
            "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_S139_median_avgsite.csv\n",
            "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_H17L19_median.csv\n",
            "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_H17L19_median_avgsite.csv\n",
            "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_H17L10_median.csv\n",
            "data/influenza/escape_doud2018/pos_map.csv\n",
            "data/influenza/escape_doud2018/H1toH3_renumber.csv\n",
            "data/influenza/escape_doud2018/WSN1933_H1_HA.fa\n",
            "data/influenza/escape_doud2018/candidates.fa\n",
            "data/influenza/ird_influenzaA_HA_allspecies.fa\n",
            "data/influenza/ird_influenzaA_HA_allspecies_meta.tsv\n",
            "data/influenza/h3_regions.txt\n",
            "data/influenza/h1_regions.txt\n",
            "data/influenza/fitness_doud2016/\n",
            "data/influenza/fitness_doud2016/Supplemental_File_5_sequencing_library_primers.txt\n",
            "data/influenza/fitness_doud2016/Supplemental_File_3_HApreferences_rescaled.txt\n",
            "data/influenza/fitness_doud2016/Doud2016_HA_replicate-2_prefs.csv\n",
            "data/influenza/fitness_doud2016/Doud2016_HA_replicate-3_prefs.csv\n",
            "data/influenza/fitness_doud2016/Doud2016_HA_replicate-1_prefs.csv\n",
            "data/influenza/fitness_doud2016/Supplemental_File_2_HApreferences.txt\n",
            "data/influenza/fitness_doud2016/Supplemental_File_6_WSN_to_H3_numbering_conversion.txt\n",
            "data/cov/\n",
            "data/cov/cov_all.fa\n",
            "data/cov/cov2_spike_wt.fasta\n",
            "data/cov/starr2020cov2/\n",
            "data/cov/starr2020cov2/binding_Kds.csv\n",
            "data/cov/starr2020cov2/expression_meanFs.csv\n",
            "data/cov/starr2020cov2/single_mut_effects.csv\n",
            "data/cov/gisaid.fasta\n",
            "data/cov/sarscov2_regions.txt\n",
            "data/cov/viprbrc_db.fasta\n",
            "data/cov/sars_cov2_seqs.fa\n",
            "data/cov/greaney2020cov2/\n",
            "data/cov/greaney2020cov2/escape_fracs.csv\n",
            "data/cov/greaney2020cov2/significant_escape_sites.csv\n",
            "data/target/\n",
            "data/target/flu/\n",
            "data/target/flu/clusters/\n",
            "data/target/flu/clusters/all_h1.fasta\n",
            "data/target/flu/clusters/all_h3.fasta\n",
            "data/target/flu/mutation/\n",
            "data/target/flu/mutation/mutations_h1.fa\n",
            "data/target/flu/mutation/mutations_h3.fa\n",
            "data/target/flu/evcouplings/\n",
            "data/target/flu/evcouplings/flu_h1/\n",
            "data/target/flu/evcouplings/flu_h1/mutate/\n",
            "data/target/flu/evcouplings/flu_h1/mutate/flu_h1_single_mutant_matrix.csv\n",
            "data/target/flu/evcouplings/flu_h3/\n",
            "data/target/flu/evcouplings/flu_h3/mutate/\n",
            "data/target/flu/evcouplings/flu_h3/mutate/flu_h3_single_mutant_matrix.csv\n",
            "data/target/flu/embedding/\n",
            "data/target/flu/embedding/tape_transformer_h1.npz\n",
            "data/target/flu/embedding/tape_transformer_h3.npz\n",
            "data/target/flu/embedding/unirep_h3.npz\n",
            "data/target/flu/embedding/unirep_h1.npz\n",
            "data/target/flu/embedding/bepler_ssa_h1.txt\n",
            "data/target/flu/embedding/bepler_ssa_h3.txt\n",
            "data/target/cov/\n",
            "data/target/cov/clusters/\n",
            "data/target/cov/clusters/all_sarscov2.fasta\n",
            "data/target/cov/mutation/\n",
            "data/target/cov/mutation/mutations_sarscov2.fa\n",
            "data/target/cov/evcouplings/\n",
            "data/target/cov/evcouplings/sarscov2/\n",
            "data/target/cov/evcouplings/sarscov2/mutate/\n",
            "data/target/cov/evcouplings/sarscov2/mutate/sarscov2_single_mutant_matrix.csv\n",
            "data/target/cov/embedding/\n",
            "data/target/cov/embedding/unirep_sarscov2.npz\n",
            "data/target/cov/embedding/tape_transformer_sarscov2.npz\n",
            "data/target/cov/embedding/bepler_ssa_sarscov2.txt\n",
            "data/target/hiv/\n",
            "data/target/hiv/clusters/\n",
            "data/target/hiv/clusters/all_BG505.fasta\n",
            "data/target/hiv/mutation/\n",
            "data/target/hiv/mutation/mutations_hiv.fa\n",
            "data/target/hiv/evcouplings/\n",
            "data/target/hiv/evcouplings/hiv_env/\n",
            "data/target/hiv/evcouplings/hiv_env/mutate/\n",
            "data/target/hiv/evcouplings/hiv_env/mutate/hiv_env_single_mutant_matrix.csv\n",
            "data/target/hiv/embedding/\n",
            "data/target/hiv/embedding/tape_transformer_hiv.npz\n",
            "data/target/hiv/embedding/unirep_hiv.npz\n",
            "data/target/hiv/embedding/bepler_ssa_hiv.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install scanpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3E_moAkkOTI",
        "outputId": "cab29d1b-608d-4751-b090-fdf80be886d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scanpy\n",
            "  Downloading scanpy-1.8.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (from scanpy) (5.5.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from scanpy) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.7/dist-packages (from scanpy) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from scanpy) (1.1.0)\n",
            "Collecting umap-learn>=0.3.10\n",
            "  Downloading umap-learn-0.5.2.tar.gz (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from scanpy) (3.1.0)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.7/dist-packages (from scanpy) (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from scanpy) (4.62.3)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.7/dist-packages (from scanpy) (2.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from scanpy) (21.3)\n",
            "Collecting sinfo\n",
            "  Downloading sinfo-0.3.4.tar.gz (24 kB)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.7/dist-packages (from scanpy) (0.5.2)\n",
            "Requirement already satisfied: importlib_metadata>=0.7 in /usr/local/lib/python3.7/dist-packages (from scanpy) (4.10.1)\n",
            "Requirement already satisfied: matplotlib>=3.1.2 in /usr/local/lib/python3.7/dist-packages (from scanpy) (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from scanpy) (0.11.2)\n",
            "Requirement already satisfied: numba>=0.41.0 in /usr/local/lib/python3.7/dist-packages (from scanpy) (0.51.2)\n",
            "Collecting anndata>=0.7.4\n",
            "  Downloading anndata-0.7.8-py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.10.0rc2 in /usr/local/lib/python3.7/dist-packages (from scanpy) (0.10.2)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.7/dist-packages (from scanpy) (3.4.4)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scanpy) (1.19.5)\n",
            "Requirement already satisfied: xlrd<2.0 in /usr/local/lib/python3.7/dist-packages (from anndata>=0.7.4->scanpy) (1.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.10.0->scanpy) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=0.7->scanpy) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=0.7->scanpy) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.2->scanpy) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.2->scanpy) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.2->scanpy) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.2->scanpy) (0.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.41.0->scanpy) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.41.0->scanpy) (0.34.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->scanpy) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.1.2->scanpy) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->scanpy) (3.1.0)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.6.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 51.9 MB/s \n",
            "\u001b[?25hCollecting stdlib_list\n",
            "  Downloading stdlib_list-0.8.0-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.7/dist-packages (from tables->scanpy) (2.8.1)\n",
            "Building wheels for collected packages: umap-learn, pynndescent, sinfo\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.2-py3-none-any.whl size=82708 sha256=0280da079144bc6165dbb7a2af2f90494864d817c170bc4b6873a8a68eeb7dde\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/1b/c6/aaf68a748122632967cef4dffef68224eb16798b6793257d82\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.6-py3-none-any.whl size=53943 sha256=cefd2f180cf67ed4e90df52c79a61466797bedcc813ff8a7db8f2fb878be9ede\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f1/56/f80d72741e400345b5a5b50ec3d929aca581bf45e0225d5c50\n",
            "  Building wheel for sinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sinfo: filename=sinfo-0.3.4-py3-none-any.whl size=7899 sha256=c9fb973faa294bdc683ca64044996dad9637174d6018d35090053ded78e91baa\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/ca/56/344d532fe53e855ccd6549795d370588ab8123907eecf4cf30\n",
            "Successfully built umap-learn pynndescent sinfo\n",
            "Installing collected packages: stdlib-list, pynndescent, umap-learn, sinfo, anndata, scanpy\n",
            "Successfully installed anndata-0.7.8 pynndescent-0.5.6 scanpy-1.8.2 sinfo-0.3.4 stdlib-list-0.8.0 umap-learn-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install anndata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93m_rusSj_7Z",
        "outputId": "e957907e-c74f-41c2-edf2-850b1d3f1153"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: anndata in /usr/local/lib/python3.7/dist-packages (0.7.8)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from anndata) (1.19.5)\n",
            "Requirement already satisfied: pandas>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from anndata) (1.3.5)\n",
            "Requirement already satisfied: importlib_metadata>=0.7 in /usr/local/lib/python3.7/dist-packages (from anndata) (4.10.1)\n",
            "Requirement already satisfied: xlrd<2.0 in /usr/local/lib/python3.7/dist-packages (from anndata) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from anndata) (3.1.0)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from anndata) (1.4.1)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (from anndata) (5.5.0)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.7/dist-packages (from anndata) (21.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=0.7->anndata) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=0.7->anndata) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20->anndata) (3.0.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.1->anndata) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.1->anndata) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.1->anndata) (1.15.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->anndata) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install bio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE5QLkJ-kWOg",
        "outputId": "7230c710-0948-44f9-ce29-9a663f9c6c2a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bio\n",
            "  Downloading bio-1.3.3-py3-none-any.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bio) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bio) (2.23.0)\n",
            "Collecting biopython>=1.79\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 42.8 MB/s \n",
            "\u001b[?25hCollecting mygene\n",
            "  Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython>=1.79->bio) (1.19.5)\n",
            "Collecting biothings-client>=0.2.6\n",
            "  Downloading biothings_client-0.2.6-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bio) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bio) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bio) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bio) (1.24.3)\n",
            "Installing collected packages: biothings-client, mygene, biopython, bio\n",
            "Successfully installed bio-1.3.3 biopython-1.79 biothings-client-0.2.6 mygene-3.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mutation import *"
      ],
      "metadata": {
        "id": "dziYgjHqlLJo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup(args):\n",
        "    fnames = [ 'data/influenza/ird_influenzaA_HA_allspecies.fa' ]\n",
        "    meta_fnames = [ 'data/influenza/ird_influenzaA_HA_allspecies_meta.tsv' ]\n",
        "\n",
        "    seqs = process(fnames, meta_fnames)\n",
        "\n",
        "    seq_len = max([ len(seq) for seq in seqs ]) + 2\n",
        "    vocab_size = len(AAs) + 2\n",
        "\n",
        "    model = get_model(args, seq_len, vocab_size)\n",
        "\n",
        "    return model, seqs\n"
      ],
      "metadata": {
        "id": "k24US6-6mnsa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process(fnames, meta_fnames):\n",
        "    metas = load_meta(meta_fnames)\n",
        "\n",
        "    seqs = {}\n",
        "    for fname in fnames:\n",
        "        for record in SeqIO.parse(fname, 'fasta'):\n",
        "            if 'Reference_Perth2009_HA_coding_sequence' in record.description:\n",
        "                continue\n",
        "            if str(record.seq).count('X') > 10:\n",
        "                continue\n",
        "            if record.seq not in seqs:\n",
        "                seqs[record.seq] = []\n",
        "            accession = record.description.split('|')[0].split(':')[1]\n",
        "            seqs[record.seq].append(metas[accession])\n",
        "    return seqs\n",
        "\n"
      ],
      "metadata": {
        "id": "y9ZhRaeeihCO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_meta(meta_fnames):\n",
        "    metas = {}\n",
        "    for fname in meta_fnames:\n",
        "        with open(fname) as f:\n",
        "            header = f.readline().rstrip().split('\\t')\n",
        "            for line in f:\n",
        "                fields = line.rstrip().split('\\t')\n",
        "                accession = fields[1]\n",
        "                meta = {}\n",
        "                for key, value in zip(header, fields):\n",
        "                    if key == 'Subtype':\n",
        "                        meta[key] = value.strip('()').split('N')[0].split('/')[-1]\n",
        "                    elif key == 'Collection Date':\n",
        "                        meta[key] = int(value.split('/')[-1]) \\\n",
        "                                    if value != '-N/A-' else None\n",
        "                    elif key == 'Host Species':\n",
        "                        meta[key] = value.split(':')[1].split('/')[-1].lower()\n",
        "                    else:\n",
        "                        meta[key] = value\n",
        "                metas[accession] = meta\n",
        "    return metas\n",
        "\n"
      ],
      "metadata": {
        "id": "l7iizod8mYuP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, seqs = setup(args)"
      ],
      "metadata": {
        "id": "0_WWb95jmggo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict \n",
        "\n",
        "seqs_subset= defaultdict(dict)\n",
        "\n",
        "for x in list(seqs)[0:3]:\n",
        "    seqs_subset[x] = seqs[x]\n",
        "\n"
      ],
      "metadata": {
        "id": "wYZU6TqInJl4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(seqs_subset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH3AifzZnJhp",
        "outputId": "1799c1f9-5932-4d4b-c331-141b02169e2a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.model_.load_weights(args.checkpoint)\n",
        "tprint('Model summary:')\n",
        "tprint(model.model_.summary())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx0JcJYGmrtn",
        "outputId": "016185ca-8f7d-4ab6-9de6-ac2da5c5675b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-06 13:05:16.184141 | Model summary:\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 577)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 577)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 577, 20)      580         ['input_1[0][0]',                \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 577, 512)     1091584     ['embedding[0][0]',              \n",
            "                                                                  'embedding[1][0]']              \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 512)          2099200     ['lstm[0][0]',                   \n",
            "                                                                  'lstm[1][0]']                   \n",
            "                                                                                                  \n",
            " embed_layer (Concatenate)      (None, 1024)         0           ['lstm_1[0][0]',                 \n",
            "                                                                  'lstm_1[1][0]']                 \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 29)           29725       ['embed_layer[0][0]']            \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 29)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,221,089\n",
            "Trainable params: 3,221,089\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "2022-02-06 13:05:16.198095 | None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#analyze_embedding(args, model, seqs, vocabulary)"
      ],
      "metadata": {
        "id": "hFlVeH0-iHBy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_embedding(args, model, seqs, vocabulary):\n",
        "    seqs = embed_seqs(args, model, seqs, vocabulary, use_cache=True)\n",
        "\n",
        "    X, obs = [], {}\n",
        "    obs['n_seq'] = []\n",
        "    obs['seq'] = []\n",
        "    for seq in seqs:\n",
        "        meta = seqs[seq][0]\n",
        "        X.append(meta['embedding'].mean(0))\n",
        "        for key in meta:\n",
        "            if key == 'embedding':\n",
        "                continue\n",
        "            if key not in obs:\n",
        "                obs[key] = []\n",
        "            obs[key].append(Counter([\n",
        "                meta[key] for meta in seqs[seq]\n",
        "            ]).most_common(1)[0][0])\n",
        "        obs['n_seq'].append(len(seqs[seq]))\n",
        "        obs['seq'].append(str(seq))\n",
        "    X = np.array(X)\n",
        "\n",
        "    adata = AnnData(X)\n",
        "    for key in obs:\n",
        "        adata.obs[key] = obs[key]\n",
        "    adata = adata[\n",
        "        np.logical_or.reduce((\n",
        "            adata.obs['Host Species'] == 'human',\n",
        "            adata.obs['Host Species'] == 'avian',\n",
        "            adata.obs['Host Species'] == 'swine',\n",
        "        ))\n",
        "    ]\n",
        "\n",
        "    sc.pp.neighbors(adata, n_neighbors=100, use_rep='X')\n",
        "    sc.tl.louvain(adata, resolution=1.)\n",
        "\n",
        "    sc.set_figure_params(dpi_save=500)\n",
        "\n",
        "    sc.tl.umap(adata, min_dist=1.)\n",
        "    plot_umap(adata)\n",
        "    plot_umap(adata[adata.obs['louvain'] == '30'],\n",
        "              namespace='flu1918')\n",
        "\n",
        "    interpret_clusters(adata)\n",
        "\n",
        "    seq_clusters(adata)"
      ],
      "metadata": {
        "id": "aAaTxFAkie5g"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/brianhie/viral-mutation/blob/master/bin/mutation.py\n",
        "def embed_seqs(args, model, seqs, vocabulary,\n",
        "               use_cache=False, verbose=True, namespace=None):\n",
        "    if namespace is None:\n",
        "        namespace = args.namespace\n",
        "\n",
        "    if 'esm' in args.model_name:\n",
        "        from fb_semantics import embed_seqs_fb\n",
        "        seqs_fb = [ seq for seq in seqs ]\n",
        "        return embed_seqs_fb(\n",
        "            model.model_, seqs_fb, model.repr_layers_, model.alphabet_,\n",
        "            use_cache=use_cache, verbose=verbose,\n",
        "        )\n",
        "\n",
        "    X_cat, lengths = featurize_seqs(seqs, vocabulary)\n",
        "\n",
        "    if use_cache:\n",
        "        mkdir_p('target/{}/embedding'.format(namespace))\n",
        "        embed_fname = ('target/{}/embedding/{}_{}.npy'\n",
        "                       .format(namespace, args.model_name, args.dim))\n",
        "    else:\n",
        "        embed_fname = None\n",
        "\n",
        "    if use_cache and os.path.exists(embed_fname):\n",
        "        X_embed = np.load(embed_fname, allow_pickle=True)\n",
        "    else:\n",
        "        model.verbose_ = verbose\n",
        "        X_embed = model.transform(X_cat, lengths, embed_fname)\n",
        "        if use_cache:\n",
        "            np.save(embed_fname, X_embed)\n",
        "\n",
        "    sorted_seqs = sorted(seqs)\n",
        "    for seq_idx, seq in enumerate(sorted_seqs):\n",
        "        for meta in seqs[seq]:\n",
        "            meta['embedding'] = X_embed[seq_idx]\n",
        "\n",
        "    return seqs"
      ],
      "metadata": {
        "id": "Bdl9HM03hkZ5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def featurize_seqs(seqs, vocabulary):\n",
        "start_int = len(vocabulary) + 1\n",
        "end_int = len(vocabulary) + 2\n"
      ],
      "metadata": {
        "id": "qAQKJc3Sh_n0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_int\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySGkiz04nqSa",
        "outputId": "40e4de3f-cb5e-4ef1-869a-f91a368500fb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "end_int"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzkWIPtpnrcW",
        "outputId": "395c0c50-e224-49cd-a3fe-9af410dc0ec1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_seqs = sorted(seqs_subset.keys())"
      ],
      "metadata": {
        "id": "E7fx-YATnsYh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sorted_seqs[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypE3iv6EpQJj",
        "outputId": "09599885-e950-44e5-d05b-b5f0590331c1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# they add a 26 before every amino acid, a 27 at the end and then concatenate it all together, all sequences \n",
        "start_int = len(vocabulary) + 1\n",
        "end_int = len(vocabulary) + 2\n",
        "sorted_seqs = sorted(seqs_subset.keys())\n",
        "X = np.concatenate([\n",
        "    np.array([ start_int ] + [\n",
        "        vocabulary[word] for word in seq \n",
        "    ] + [ end_int ]) for seq in sorted_seqs]).reshape(-1, 1)\n",
        "lens = np.array([ len(seq) + 2 for seq in sorted_seqs ])\n",
        "assert(sum(lens) == X.shape[0])\n",
        "#return X, lens"
      ],
      "metadata": {
        "id": "J3kn_X64n-dM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " np.concatenate([np.array([ start_int ] + [vocabulary[word] for word in seq ] + [ end_int ]) for seq in sorted_seqs[0] ] ).reshape(-1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYsVijtirKJR",
        "outputId": "0cca3f6c-3d15-4aa8-9b14-b1db0489bf03"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[26],\n",
              "       [13],\n",
              "       [27],\n",
              "       ...,\n",
              "       [26],\n",
              "       [ 9],\n",
              "       [27]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#564\n",
        "X.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3mHi1N9pZcX",
        "outputId": "76cde795-6209-4c40-c897-706ded89412f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1697, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "567+568+562"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPe5otFDI8T1",
        "outputId": "3b36215f-4259-43ed-b22e-daea13aabeab"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1697"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lens"
      ],
      "metadata": {
        "id": "fBMaHTSUpZYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "160c7bcf-cc02-4c3a-8fd0-32f5aa280c3a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([567, 568, 562])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "namespace = args.namespace\n",
        "#if use_cache:\n",
        "mkdir_p('target/{}/embedding'.format(namespace))\n",
        "embed_fname = ('target/{}/embedding/{}_{}.npy'\n",
        "                .format(namespace, args.model_name, args.dim))"
      ],
      "metadata": {
        "id": "BE-2Zic-pZWS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_fname"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_jbt3w1b8bJ5",
        "outputId": "853a1a18-e7af-404c-effe-54dbf43a2b3b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'target/flu/embedding/bilstm_512.npy'"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ctrl+/ to comment all lines\n",
        "\n",
        "# model.verbose_ = verbose\n",
        "# X_embed = model.transform(X_cat, lengths, embed_fname)\n",
        "# if use_cache:\n",
        "#     np.save(embed_fname, X_embed)\n"
      ],
      "metadata": {
        "id": "QA52U_Qa8hts"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   def transform(self, X_cat, lengths, embed_fname=None):\n",
        "        X = self.split_and_pad(\n",
        "            X_cat, lengths,\n",
        "            self.seq_len_, self.vocab_size_, self.verbose_,\n",
        "        )[0]\n",
        "\n",
        "        # For now, each character in each sequence becomes a sample.\n",
        "        n_samples = sum(lengths)\n",
        "        if type(X) == list:\n",
        "            for X_i in X:\n",
        "                assert(X_i.shape[0] == n_samples)\n",
        "        else:\n",
        "            assert(X.shape[0] == n_samples)\n",
        "\n",
        "        # Embed using the output of a hidden layer.\n",
        "        hidden = tf.keras.backend.function(\n",
        "            inputs=self.model_.input,\n",
        "            outputs=self.model_.get_layer('embed_layer').output,\n",
        "        )\n",
        "\n",
        "        # Manage batching to avoid overwhelming GPU memory.\n",
        "        X_embed_cat = []\n",
        "        n_batches = math.ceil(n_samples / self.inference_batch_size_)\n",
        "        if self.verbose_:\n",
        "            tprint('Embedding...')\n",
        "            prog_bar = tf.keras.utils.Progbar(n_batches)\n",
        "        for batchi in range(n_batches):\n",
        "            start = batchi * self.inference_batch_size_\n",
        "            end = min((batchi + 1) * self.inference_batch_size_, n_samples)\n",
        "            if type(X) == list:\n",
        "                X_batch = [ X_i[start:end] for X_i in X ]\n",
        "            else:\n",
        "                X_batch = X[start:end]\n",
        "            X_embed_cat.append(hidden(X_batch))\n",
        "            if self.verbose_:\n",
        "                prog_bar.add(1)\n",
        "        X_embed_cat = np.concatenate(X_embed_cat)\n",
        "        if self.verbose_:\n",
        "            tprint('Done embedding.')\n",
        "\n",
        "        X_embed = np.array([\n",
        "            X_embed_cat[start:end]\n",
        "            for start, end in\n",
        "            iterate_lengths(lengths, self.seq_len_)\n",
        "        ])\n",
        "\n",
        "        return X_embed"
      ],
      "metadata": {
        "id": "Fu0IOQVA9LiW"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_batches = math.ceil(1697 / 1500)\n",
        "n_batches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjBofuplNH4_",
        "outputId": "c1482a03-fbe5-4089-cc82-2ce85b8057fc"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# two batches because we have batch size 1500 and 1697 samples\n",
        " X_embed = model.transform(X, lens, embed_fname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRRs2UQeAn51",
        "outputId": "640d7ea6-baac-41df-8f2b-957191f77e1f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-06 13:05:52.922761 | Embedding...\n",
            "2/2 [==============================] - 358s 53s/step\n",
            "2022-02-06 13:11:50.696413 | Done embedding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "viral-mutation/bin/language_model.py:114: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  iterate_lengths(lengths, self.seq_len_)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.inference_batch_size_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD2MnfdlJHyI",
        "outputId": "d0e49eda-fd9a-4427-d797-2c58a1e85a7d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_embed.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Yo8Jr8Lhld",
        "outputId": "148a07f8-8aa2-4651-d98f-1c285a932630"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of signle sequence embedding\n",
        "# 562 rows (number of tokens), 1024 columns\n",
        "X_embed[2].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL0uxp5-BrYZ",
        "outputId": "ff53f067-e8a3-4216-c160-85c99b8b0111"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(562, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saves embeddings \n",
        "np.save(embed_fname, X_embed)"
      ],
      "metadata": {
        "id": "ed5InjACECi9"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add embedding to sequence dictionary\n",
        "sorted_seqs = sorted(seqs_subset)\n",
        "for seq_idx, seq in enumerate(sorted_seqs):\n",
        "    for meta in seqs_subset[seq]:\n",
        "        meta['embedding'] = X_embed[seq_idx]"
      ],
      "metadata": {
        "id": "Ep_xfZMNMKyv"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seqs_subset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aRuOyjzMdtB",
        "outputId": "d9eb06b7-3c86-4b94-a821-6f1ced7d447e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(dict,\n",
              "            {Seq('MKAKLLVLLYAFVATDADTICIGYHANNSTDTVDTIFEKNVAVTHSVNLLEDRH...ICI'): [{'Collection Date': 1933,\n",
              "               'Complete Genome': 'Yes',\n",
              "               'Country': 'United Kingdom',\n",
              "               'Flu Season': '-N/A-',\n",
              "               'Host Species': 'human',\n",
              "               'Name': 'HA',\n",
              "               'Segment': '4',\n",
              "               'Segment Length': '1775',\n",
              "               'Sequence Accession': 'J02176',\n",
              "               'State/Province': '-N/A-',\n",
              "               'Strain Name': 'A/WSN/1933',\n",
              "               'Subtype': 'H1',\n",
              "               'embedding': array([[-4.0876325e-03,  4.7387434e-03,  3.0577895e-01, ...,\n",
              "                        5.9461594e-04,  1.7255545e-04,  2.7135708e-03],\n",
              "                      [-4.7921322e-04,  9.3112969e-01,  2.4222764e-03, ...,\n",
              "                        2.7651529e-05,  3.3582181e-02,  2.0789664e-02],\n",
              "                      [-6.6961989e-02,  2.5158213e-03,  2.0701651e-04, ...,\n",
              "                        9.5871091e-04,  4.0051639e-03,  4.0889871e-01],\n",
              "                      ...,\n",
              "                      [-9.8514193e-01,  1.4412403e-04,  7.4837526e-04, ...,\n",
              "                        7.4411830e-05,  3.4993782e-04,  9.6720457e-03],\n",
              "                      [-8.3218254e-02,  8.7167686e-01,  3.0631352e-05, ...,\n",
              "                        3.3770730e-06,  2.7611788e-04,  1.9304484e-02],\n",
              "                      [-5.2683318e-01,  1.5569449e-05,  5.4201819e-03, ...,\n",
              "                        4.6852001e-06,  2.4652420e-04,  9.4835460e-03]], dtype=float32)}],\n",
              "             Seq('MKARLLVLLCALAATDADTICIGYHANNSTDTVDTVLEKNVTVTHSVNLLEDSH...ICI'): [{'Collection Date': 1945,\n",
              "               'Complete Genome': 'Yes',\n",
              "               'Country': 'USA',\n",
              "               'Flu Season': '-N/A-',\n",
              "               'Host Species': 'human',\n",
              "               'Name': 'HA',\n",
              "               'Segment': '4',\n",
              "               'Segment Length': '1751',\n",
              "               'Sequence Accession': 'CY021709',\n",
              "               'State/Province': 'Texas',\n",
              "               'Strain Name': 'A/AA/Huston/1945',\n",
              "               'Subtype': 'H1',\n",
              "               'embedding': array([[-4.0876325e-03,  4.7387434e-03,  3.0577895e-01, ...,\n",
              "                        6.1702728e-04,  2.2348762e-04,  3.0324068e-03],\n",
              "                      [-4.7921322e-04,  9.3112969e-01,  2.4222764e-03, ...,\n",
              "                        9.3915769e-05,  2.1597207e-02,  3.8746521e-02],\n",
              "                      [-6.6961989e-02,  2.5158213e-03,  2.0701651e-04, ...,\n",
              "                        1.6278028e-03,  8.1862807e-03,  8.0525887e-01],\n",
              "                      ...,\n",
              "                      [-9.8520768e-01,  1.4403462e-04,  7.3508616e-04, ...,\n",
              "                        7.4411830e-05,  3.4993782e-04,  9.6720457e-03],\n",
              "                      [-8.2754187e-02,  8.7395322e-01,  3.0878899e-05, ...,\n",
              "                        3.3770730e-06,  2.7611788e-04,  1.9304484e-02],\n",
              "                      [-5.1950163e-01,  1.5458780e-05,  5.5347132e-03, ...,\n",
              "                        4.6852001e-06,  2.4652420e-04,  9.4835460e-03]], dtype=float32)}],\n",
              "             Seq('MNTQILVFIACVLIEAKGDKICLGHHAVANGTKVNTLTERGIEVVNATETVETA...ICI'): [{'Collection Date': 1980,\n",
              "               'Complete Genome': 'No',\n",
              "               'Country': 'USA',\n",
              "               'Flu Season': '-N/A-',\n",
              "               'Host Species': 'sea mammal',\n",
              "               'Name': 'HA',\n",
              "               'Segment': '4',\n",
              "               'Segment Length': '1730',\n",
              "               'Sequence Accession': 'K00429',\n",
              "               'State/Province': 'Massachusetts',\n",
              "               'Strain Name': 'A/seal/Mass/1/1980',\n",
              "               'Subtype': 'H7',\n",
              "               'embedding': array([[-4.08763252e-03,  4.73874342e-03,  3.05778950e-01, ...,\n",
              "                        2.61068344e-04,  1.46940351e-03,  1.24275684e-03],\n",
              "                      [-4.79213224e-04,  9.31129694e-01,  2.42227642e-03, ...,\n",
              "                        3.76509843e-06,  9.42406058e-03,  2.15065181e-02],\n",
              "                      [-6.69619888e-02,  2.51582125e-03,  2.07016506e-04, ...,\n",
              "                        2.62915073e-05,  3.72231007e-04,  1.67287499e-01],\n",
              "                      ...,\n",
              "                      [-9.96479511e-01,  1.78277493e-04,  1.23053556e-02, ...,\n",
              "                        7.44118297e-05,  3.49937822e-04,  9.67204571e-03],\n",
              "                      [-5.47727466e-01,  7.22489953e-01,  6.24291624e-06, ...,\n",
              "                        3.37707297e-06,  2.76117877e-04,  1.93044841e-02],\n",
              "                      [-8.52277339e-01,  1.02962505e-04,  9.83815640e-04, ...,\n",
              "                        4.68520466e-06,  2.46613607e-04,  9.48354602e-03]], dtype=float32)}]})"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for each token they take the average of the embedding across the 1024 columns\n",
        "# axis=0 is columns\n",
        "X=[]\n",
        "for seq in seqs_subset:\n",
        "    meta = seqs_subset[seq][0]\n",
        "    X.append(meta['embedding'].mean(0))"
      ],
      "metadata": {
        "id": "iZzQBXqJN-AO"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTbfxdBKOWEf",
        "outputId": "162358f8-12d8-4105-922e-04d9c3d79233"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[len(i) for i in X]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvTlyagBOZVB",
        "outputId": "f6684120-4f9d-487d-d17b-62a4789ab607"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1024, 1024, 1024]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, obs = [], {}\n",
        "obs['n_seq'] = []\n",
        "obs['seq'] = []\n",
        "for seq in seqs_subset:\n",
        "    meta = seqs_subset[seq][0]\n",
        "    X.append(meta['embedding'].mean(0))\n",
        "    for key in meta:\n",
        "        if key == 'embedding':\n",
        "            continue\n",
        "        if key not in obs:\n",
        "            obs[key] = []\n",
        "        obs[key].append(Counter([\n",
        "            meta[key] for meta in seqs_subset[seq]\n",
        "        ]).most_common(1)[0][0])\n",
        "    obs['n_seq'].append(len(seqs_subset[seq]))\n",
        "    obs['seq'].append(str(seq))\n",
        "X = np.array(X)"
      ],
      "metadata": {
        "id": "pOQronePMiCH"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-99uwXQcNb2z",
        "outputId": "c30c04a8-276d-47c5-89c0-35f982a3eb88"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.21952093,  0.15302822,  0.08027752, ...,  0.15850776,\n",
              "         0.4371412 ,  0.24013731],\n",
              "       [-0.2164791 ,  0.15193553,  0.08483234, ...,  0.14954166,\n",
              "         0.44265613,  0.22463955],\n",
              "       [-0.21291347,  0.15359351,  0.07886145, ...,  0.14754881,\n",
              "         0.42821074,  0.2195413 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFRV0070Ng2U",
        "outputId": "4345f33d-8b7c-4ce1-ec6b-8268e2abfcd5"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Collection Date': [1980, 1933, 1945],\n",
              " 'Complete Genome': ['No', 'Yes', 'Yes'],\n",
              " 'Country': ['USA', 'United Kingdom', 'USA'],\n",
              " 'Flu Season': ['-N/A-', '-N/A-', '-N/A-'],\n",
              " 'Host Species': ['sea mammal', 'human', 'human'],\n",
              " 'Name': ['HA', 'HA', 'HA'],\n",
              " 'Segment': ['4', '4', '4'],\n",
              " 'Segment Length': ['1730', '1775', '1751'],\n",
              " 'Sequence Accession': ['K00429', 'J02176', 'CY021709'],\n",
              " 'State/Province': ['Massachusetts', '-N/A-', 'Texas'],\n",
              " 'Strain Name': ['A/seal/Mass/1/1980', 'A/WSN/1933', 'A/AA/Huston/1945'],\n",
              " 'Subtype': ['H7', 'H1', 'H1'],\n",
              " 'n_seq': [1, 1, 1],\n",
              " 'seq': ['MNTQILVFIACVLIEAKGDKICLGHHAVANGTKVNTLTERGIEVVNATETVETANIGKICTQGKRPTDLGQCGLLGTLIGPPQCDQFLEFESNLIIERREGNDVCYPGKFTNEESLRQILRGSGGVDKESMGFTYSGIRTNGTTSACRRSGSSFYAEMKWLLSNSDNAAFPQMTKSYRNPRNKPALIVWGIHHSGSTTEQTRLYGSGNKLITVGSSKYQQSFTPSPGARPQVNGQSGRIDFHWLLLDPNDTVTFTFNGAFIAPNRASFFRGESLGVQSDVPLDSNCGGDCFHSGGTIVSSLPFQNINSRTVGKCPRYVKQPSLLLATGMRNVPENPKTRGLFGAIAGFIENGWEGLIDGWYGFRHQNAQGEGTAADYKSTQSAIDQITGKLNRLIDKTNQQFELIDNEFNEIEQQIGNVINWTRDSMTEVWSYNAELLVAMENQHTIDLADSEMNKLYERVRKQLRENAEEDGTGCFEIFHKCDDQCMESIRNNTYDHTQYRAKSLQNRIQIDPVKLSSGYKDIILWFSFGASCFLLLAIAMGLVFICIKNGNMRCTICI',\n",
              "  'MKAKLLVLLYAFVATDADTICIGYHANNSTDTVDTIFEKNVAVTHSVNLLEDRHNGKLCKLKGIAPLQLGKCNITGWLLGNPECDSLLPARSWSYIVETPNSENGACYPGDFIDYEELREQLSSVSSLERFEIFPKESSWPNHTFNGVTVSCSHRGKSSFYRNLLWLTKKGDSYPKLTNSYVNNKGKEVLVLWGVHHPSSSDEQQSLYSNGNAYVSVASSNYNRRFTPEIAARPKVKDQHGRMNYYWTLLEPGDTIIFEATGNLIAPWYAFALSRGFESGIITSNASMHECNTKCQTPQGSINSNLPFQNIHPVTIGECPKYVRSTKLRMVTGLRNIPSIQYRGLFGAIAGFIEGGWTGMIDGWYGYHHQNEQGSGYAADQKSTQNAINGITNKVNSVIEKMNTQFTAVGKEFNNLEKRMENLNKKVDDGFLDIWTYNAELLVLLENERTLDFHDLNVKNLYEKVKSQLKNNAKEIGNGCFEFYHKCDNECMESVRNGTYDYPKYSEESKLNREKIDGVKLESMGVYQILAIYSTVASSLVLLVSLGAISFWMCSNGSLQCRICI',\n",
              "  'MKARLLVLLCALAATDADTICIGYHANNSTDTVDTVLEKNVTVTHSVNLLEDSHNGKLCRLKGIAPLQLRKCNIAGWILGNPECESLLSERSWSYIVETPNSENGTCYPGDFTNYEELREQLSSVSSFERFEIFPKESSWPKHNTTRGVTAACSHAGKSSFYRNLLWLTEKDGSYPNLNNSYVNKKGKEVLVLWGVHHPSNIKDQQTLYQKENAYVSVVSSNYNRRFTPEIAERPKVRGQAGRMNYYWTLLKPGDTIMFEANGNLIAPWYAFALSRGFGSGIITSNASMHECDTKCQTPQGAINSSLPFQNIHPVTIGECPKYVRSTKLRMVTGLRNIPSIQSRGLFGAIAGFIEGGWTGMIDGWYGYHHQNEQGSGYAADQKSTQNAINGITNKVNSVIEKMNTQFTAVGKEFNNLEKRMENLNKKVDDGFLDIWTYNAELLILLENERTLDFHDSNVKNLYEKVKSQLRNNAKEIGNGCFEFYHKCNNECMESVKNGTYDYPKYSEESKLNREKIDGVKLESMGVYQILAIYSTVASSLVLLVSLGAISFWMCSNGSLQCRICI']}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " adata = AnnData(X)\n",
        "for key in obs:\n",
        "    adata.obs[key] = obs[key]\n",
        "adata = adata[\n",
        "    np.logical_or.reduce((\n",
        "        adata.obs['Host Species'] == 'human',\n",
        "        adata.obs['Host Species'] == 'avian',\n",
        "        adata.obs['Host Species'] == 'swine',\n",
        "    ))\n",
        "]"
      ],
      "metadata": {
        "id": "zGdjQiaINtbi"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTz01chCPlZe",
        "outputId": "21a11226-be99-4e8b-ec72-08b5ba7bb446"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "View of AnnData object with n_obs × n_vars = 2 × 1024\n",
              "    obs: 'n_seq', 'seq', 'Name', 'Sequence Accession', 'Complete Genome', 'Segment', 'Segment Length', 'Subtype', 'Collection Date', 'Host Species', 'Country', 'State/Province', 'Flu Season', 'Strain Name'"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sc is scanpy\n",
        "# https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.neighbors.html\n",
        "# Compute a neighborhood graph of observations [McInnes18].\n",
        "sc.pp.neighbors(adata, n_neighbors=2, use_rep='X')"
      ],
      "metadata": {
        "id": "wEhay518QQ8_"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install igraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiqCor_TQsAt",
        "outputId": "4a5c532f-9387-4fa1-e276-965f85e7fe7b"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: igraph in /usr/local/lib/python3.7/dist-packages (0.9.9)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from igraph) (1.6.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install louvain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLsg3O5QQ2yE",
        "outputId": "5673b8fa-4f85-4014-d300-43eddea299ee"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: louvain in /usr/local/lib/python3.7/dist-packages (0.7.1)\n",
            "Requirement already satisfied: igraph>=0.9.5 in /usr/local/lib/python3.7/dist-packages (from louvain) (0.9.9)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from igraph>=0.9.5->louvain) (1.6.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cluster cells using the Louvain algorithm [Blondel08] in the implementation of [Traag17]. The Louvain algorithm has been proposed for single-cell analysis\n",
        "sc.tl.louvain(adata, resolution=1.)"
      ],
      "metadata": {
        "id": "Z0TMvLRsQTFN"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc.set_figure_params(dpi_save=500)\n",
        "\n",
        "sc.tl.umap(adata, min_dist=1.)\n",
        "plot_umap(adata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "s0cpyh8EQzCq",
        "outputId": "65959937-8de3-47c7-878c-44c59ababd49"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/eigen/arpack/arpack.py:1592: RuntimeWarning: k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
            "  RuntimeWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-595014696848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_figure_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpi_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mumap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplot_umap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scanpy/tools/_umap.py\u001b[0m in \u001b[0;36mumap\u001b[0;34m(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mneigh_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mneigh_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metric_kwds'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbosity\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rapids'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scanpy/tools/_umap.py\u001b[0m in \u001b[0;36msimplicial_set_embedding\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mdensmap_kwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0moutput_dens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             )\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mX_umap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36msimplicial_set_embedding\u001b[0;34m(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, densmap, densmap_kwds, output_dens, output_metric, output_metric_kwds, euclidean_output, parallel, verbose, tqdm_kwds)\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m             \u001b[0mmetric_kwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_kwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m         )\n\u001b[1;32m   1086\u001b[0m         \u001b[0mexpansion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitialisation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/umap/spectral.py\u001b[0m in \u001b[0;36mspectral_layout\u001b[0;34m(data, graph, dim, random_state, metric, metric_kwds)\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mv0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             )\n\u001b[1;32m    341\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/eigen/arpack/arpack.py\u001b[0m in \u001b[0;36meigsh\u001b[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             raise TypeError(\"Cannot use scipy.linalg.eigh for sparse A with \"\n\u001b[0m\u001b[1;32m   1596\u001b[0m                             \u001b[0;34m\"k >= N. Use scipy.linalg.eigh(A.toarray()) or\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                             \" reduce k.\")\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rmVzBEvARE5L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}